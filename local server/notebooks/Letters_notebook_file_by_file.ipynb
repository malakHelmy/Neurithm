{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwvEujjRmZvh",
        "outputId": "22cb09a4-5c58-4413-ec26-77e53c2e9471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-1.9.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne) (24.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.11/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from mne) (1.14.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.5->mne) (2.32.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.1.31)\n",
            "Downloading mne-1.9.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne\n",
            "Successfully installed mne-1.9.0\n",
            "Collecting mne-icalabel\n",
            "  Downloading mne_icalabel-0.7.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: mne>=1.2 in /usr/local/lib/python3.11/dist-packages (from mne-icalabel) (1.9.0)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from mne-icalabel) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mne-icalabel) (24.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.11/dist-packages (from mne-icalabel) (1.8.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from mne-icalabel) (5.9.5)\n",
            "Requirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mne-icalabel) (1.14.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from mne>=1.2->mne-icalabel) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from mne>=1.2->mne-icalabel) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.11/dist-packages (from mne>=1.2->mne-icalabel) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.6 in /usr/local/lib/python3.11/dist-packages (from mne>=1.2->mne-icalabel) (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from mne>=1.2->mne-icalabel) (4.67.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch->mne-icalabel) (4.3.7)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pooch->mne-icalabel) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.2->mne-icalabel) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.2->mne-icalabel) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.2->mne-icalabel) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.2->mne-icalabel) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.2->mne-icalabel) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.2->mne-icalabel) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.6->mne>=1.2->mne-icalabel) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->mne-icalabel) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->mne-icalabel) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->mne-icalabel) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pooch->mne-icalabel) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->mne>=1.2->mne-icalabel) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6->mne>=1.2->mne-icalabel) (1.17.0)\n",
            "Downloading mne_icalabel-0.7.0-py3-none-any.whl (21.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.6/21.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mne-icalabel\n",
            "Successfully installed mne-icalabel-0.7.0\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.14.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->keras-tuner) (2025.1.31)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras->keras-tuner) (4.13.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install mne\n",
        "!pip install mne-icalabel\n",
        "!pip install keras-tuner\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJOmbvv1m1Mk",
        "outputId": "b53b8db9-df9d-4148-cb5a-a2d0218b9c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Libraries imported and constants initialized.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "from mne.preprocessing import ICA\n",
        "from mne_icalabel import label_components\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "\n",
        "# Constants\n",
        "FS = 128  # Sampling frequency\n",
        "METADATA_COLUMNS =  [\n",
        "    'EEG.Counter', 'EEG.Interpolated', 'EEG.RawCq', 'EEG.Battery',\n",
        "    'EEG.BatteryPercent', 'EEG.MarkerHardware'\n",
        "]\n",
        "\n",
        "print(\"Libraries imported and constants initialized.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqewA0uZm7rb",
        "outputId": "c1826793-8b87-493e-892b-501e7e099325"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing letter folder: .ipynb_checkpoints\n",
            "Processing letter folder: ق\n",
            "  Skipping .ipynb_checkpoints (not a .csv file)\n",
            "  Reading participant file: par.12 الف_EPOCX_194172_2023.12.02T14.17.46+03.00.md.csv\n",
            "\n",
            "Total samples loaded: 1\n",
            "Example entry:\n",
            "Participant: par.12, Label: ق\n",
            "      Timestamp  OriginalTimestamp  EEG.Counter  EEG.Interpolated  \\\n",
            "0  1.701516e+09       1.701516e+09         69.0               0.0   \n",
            "1  1.701516e+09       1.701516e+09         70.0               0.0   \n",
            "2  1.701516e+09       1.701516e+09         71.0               0.0   \n",
            "3  1.701516e+09       1.701516e+09         72.0               0.0   \n",
            "4  1.701516e+09       1.701516e+09         73.0               0.0   \n",
            "\n",
            "       EEG.AF3       EEG.F7       EEG.F3      EEG.FC5       EEG.T7  \\\n",
            "0  4259.358887  4317.563965  4332.179688  4329.230957  4306.025879   \n",
            "1  4264.102539  4319.358887  4336.538574  4336.538574  4305.128418   \n",
            "2  4282.179688  4332.307617  4347.820313  4343.717773  4310.512695   \n",
            "3  4299.743652  4339.487305  4362.307617  4348.974121  4315.256348   \n",
            "4  4306.538574  4338.077148  4369.871582  4354.102539  4311.922852   \n",
            "\n",
            "        EEG.P7  ...    MOT.Q0    MOT.Q1    MOT.Q2    MOT.Q3  MOT.AccX  \\\n",
            "0  4296.410156  ...       NaN       NaN       NaN       NaN       NaN   \n",
            "1  4304.358887  ...       NaN       NaN       NaN       NaN       NaN   \n",
            "2  4314.358887  ...       NaN       NaN       NaN       NaN       NaN   \n",
            "3  4311.666504  ...  0.691021  0.210999 -0.595581  0.351074   0.97424   \n",
            "4  4306.666504  ...       NaN       NaN       NaN       NaN       NaN   \n",
            "\n",
            "   MOT.AccY  MOT.AccZ   MOT.MagX  MOT.MagY   MOT.MagZ  \n",
            "0       NaN       NaN        NaN       NaN        NaN  \n",
            "1       NaN       NaN        NaN       NaN        NaN  \n",
            "2       NaN       NaN        NaN       NaN        NaN  \n",
            "3 -0.121109  0.197778  11.988317   4.22358  91.387093  \n",
            "4       NaN       NaN        NaN       NaN        NaN  \n",
            "\n",
            "[5 rows x 68 columns]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "# Function to load and preprocess each participant's EEG CSV individually\n",
        "def load_dataset_file_by_file(root_folder):\n",
        "    dataset = []  # List of tuples: (dataframe, label, participant_id)\n",
        "\n",
        "    for letter_folder in sorted(os.listdir(root_folder)):  # Optional: sort for consistency\n",
        "        letter_path = os.path.join(root_folder, letter_folder)\n",
        "        if not os.path.isdir(letter_path):\n",
        "            print(f\"Skipping {letter_path} (not a directory)\")\n",
        "            continue\n",
        "\n",
        "        print(f\"Processing letter folder: {letter_folder}\")\n",
        "        label = letter_folder  # Use folder name as label\n",
        "\n",
        "        for file in os.listdir(letter_path):\n",
        "            file_path = os.path.join(letter_path, file)\n",
        "            if not os.path.isfile(file_path) or not file.endswith('.csv'):\n",
        "                print(f\"  Skipping {file} (not a .csv file)\")\n",
        "                continue\n",
        "\n",
        "            print(f\"  Reading participant file: {file}\")\n",
        "            try:\n",
        "                df = pd.read_csv(file_path, skiprows=1)\n",
        "\n",
        "                # Extract participant name using regex\n",
        "                match = re.match(r'(par\\.\\d+)', file)\n",
        "                participant_name = match.group(0) if match else \"unknown\"\n",
        "\n",
        "                # Append as a tuple: (dataframe, label, participant_id)\n",
        "                dataset.append((df, label, participant_name))\n",
        "            except Exception as e:\n",
        "                print(f\"  Error reading {file_path}: {e}\")\n",
        "                continue\n",
        "\n",
        "    return dataset\n",
        "\n",
        "# Example usage\n",
        "ROOT_FOLDER = \"/content/drive/MyDrive/ArEEG_Chars/أحر\"\n",
        "dataset = load_dataset_file_by_file(ROOT_FOLDER)\n",
        "\n",
        "# Check an example\n",
        "print(f\"\\nTotal samples loaded: {len(dataset)}\")\n",
        "print(\"Example entry:\")\n",
        "df_sample, label_sample, participant_sample = dataset[0]\n",
        "print(f\"Participant: {participant_sample}, Label: {label_sample}\")\n",
        "print(df_sample.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAfaPDEJSqut",
        "outputId": "2d173766-f02f-4ddf-db85-2390390ad055"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔍 Processing sample 1/1 - Participant: par.12, Label: ق\n",
            "  ✅ Validating data with shape: (1384, 68)\n",
            "\n",
            "✅ EEG validation complete. Valid samples: 1, Skipped: 0\n",
            "\n",
            "👤 Participant: par.12, 🏷️ Label: ق, 📐 EEG shape: (1384, 20)\n"
          ]
        }
      ],
      "source": [
        "# Metadata columns to exclude from EEG signal channels\n",
        "METADATA_COLUMNS = ['Time', 'Event Id', 'Event Date', 'Event Duration', 'Event Description']\n",
        "\n",
        "# Function to validate EEG data for a single DataFrame\n",
        "def validate_eeg_data(df):\n",
        "    # Keep only EEG channels (not metadata)\n",
        "    valid_columns = [col for col in df.columns if col.startswith('EEG.') and col not in METADATA_COLUMNS]\n",
        "\n",
        "    if not valid_columns:\n",
        "        print(\"  ❌ No valid EEG signal columns identified. Skipping this DataFrame.\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"  ✅ Validating data with shape: {df.shape}\")\n",
        "    return df[valid_columns].copy(), valid_columns\n",
        "\n",
        "# Function to validate all entries in the dataset\n",
        "def validate_all_eeg_data(dataset):\n",
        "    validated_dataset = []           # Will store (cleaned_df, label, participant)\n",
        "    valid_columns_map = {}           # Optional: track valid columns per participant\n",
        "    skipped = 0\n",
        "\n",
        "    for idx, (df, label, participant) in enumerate(dataset):\n",
        "        print(f\"\\n🔍 Processing sample {idx + 1}/{len(dataset)} - Participant: {participant}, Label: {label}\")\n",
        "        validated_df, valid_columns = validate_eeg_data(df)\n",
        "\n",
        "        if validated_df is not None:\n",
        "            validated_dataset.append((validated_df, label, participant))\n",
        "            valid_columns_map[participant] = valid_columns\n",
        "        else:\n",
        "            print(f\"  ⚠️ Skipping sample from {participant}\")\n",
        "            skipped += 1\n",
        "\n",
        "    print(f\"\\n✅ EEG validation complete. Valid samples: {len(validated_dataset)}, Skipped: {skipped}\")\n",
        "    return validated_dataset, valid_columns_map\n",
        "\n",
        "# Run validation\n",
        "validated_dataset, valid_columns_map = validate_all_eeg_data(dataset)\n",
        "\n",
        "# Optional: Preview\n",
        "df_example, label_example, participant_example = validated_dataset[0]\n",
        "print(f\"\\n👤 Participant: {participant_example}, 🏷️ Label: {label_example}, 📐 EEG shape: {df_example.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEPdwBrCYkde",
        "outputId": "c90cf2cb-1238-42ac-9d44-d47345b44495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧹 Cleaning sample 1/1 - Participant: par.12, Label: ق\n",
            "  Removed channels: ['EEG.O2', 'EEG.FC6']\n",
            "  Shape after cleaning: (1384, 12)\n",
            "\n",
            "✅ Finished cleaning all EEG samples. Total cleaned samples: 1\n",
            "\n",
            "👤 Participant: par.12, 🏷️ Label: ق, 📐 Cleaned EEG shape: (1384, 12)\n"
          ]
        }
      ],
      "source": [
        "# ✅ Final list of channels to keep after removing EEG.O2 and EEG.FC6\n",
        "DESIRED_EEG_CHANNELS = [\n",
        "    'EEG.AF3', 'EEG.F7', 'EEG.F3', 'EEG.FC5', 'EEG.T7', 'EEG.P7',\n",
        "    'EEG.O1', 'EEG.P8', 'EEG.T8', 'EEG.F4', 'EEG.F8', 'EEG.AF4'\n",
        "]\n",
        "\n",
        "def clean_validated_dataset(validated_dataset):\n",
        "    cleaned_dataset = []\n",
        "\n",
        "    for idx, (df, label, participant) in enumerate(validated_dataset):\n",
        "        print(f\"\\n🧹 Cleaning sample {idx + 1}/{len(validated_dataset)} - Participant: {participant}, Label: {label}\")\n",
        "\n",
        "        # Select only the desired EEG channels (intersection in case some are missing)\n",
        "        available_channels = [ch for ch in DESIRED_EEG_CHANNELS if ch in df.columns]\n",
        "        df_cleaned = df[available_channels].copy()\n",
        "\n",
        "        removed_channels = [ch for ch in ['EEG.O2', 'EEG.FC6'] if ch in df.columns]\n",
        "        print(f\"  Removed channels: {removed_channels}\")\n",
        "        print(f\"  Shape after cleaning: {df_cleaned.shape}\")\n",
        "\n",
        "        cleaned_dataset.append((df_cleaned, label, participant))\n",
        "\n",
        "    print(f\"\\n✅ Finished cleaning all EEG samples. Total cleaned samples: {len(cleaned_dataset)}\")\n",
        "    return cleaned_dataset\n",
        "\n",
        "\n",
        "# Run the cleaning step\n",
        "cleaned_dataset = clean_validated_dataset(validated_dataset)\n",
        "\n",
        "# Example check\n",
        "df_clean, label_clean, participant_clean = cleaned_dataset[0]\n",
        "print(f\"\\n👤 Participant: {participant_clean}, 🏷️ Label: {label_clean}, 📐 Cleaned EEG shape: {df_clean.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Onb4OAWrYwB2",
        "outputId": "6bd42543-123c-4c82-c154-bc2bcc39bcc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧠 Creating Raw object 1/1 - Participant: par.12, Label: ق\n",
            "  ✅ Successfully created and renamed Raw object.\n"
          ]
        }
      ],
      "source": [
        "import mne\n",
        "\n",
        "FS = 128  # Set your actual sampling frequency here\n",
        "\n",
        "# Function to create an MNE Raw object\n",
        "def create_raw_object(eeg_data, sfreq=FS):\n",
        "    data = eeg_data.to_numpy().T  # Transpose to shape (n_channels, n_times)\n",
        "    ch_names = eeg_data.columns.tolist()\n",
        "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types=['eeg'] * len(ch_names))\n",
        "    raw = mne.io.RawArray(data, info, verbose=False)\n",
        "    return raw\n",
        "\n",
        "# Function to rename EEG channels for standard montage compatibility\n",
        "def rename_eeg_channels(raw_object):\n",
        "    rename_dict = {\n",
        "        'EEG.AF3': 'AF3', 'EEG.AF4': 'AF4', 'EEG.F7': 'F7',\n",
        "        'EEG.F3': 'F3', 'EEG.FC5': 'FC5', 'EEG.T7': 'T7',\n",
        "        'EEG.P7': 'P7', 'EEG.O1': 'O1', 'EEG.P8': 'P8',\n",
        "        'EEG.T8': 'T8', 'EEG.F4': 'F4', 'EEG.F8': 'F8'\n",
        "    }\n",
        "    raw_object.rename_channels(rename_dict)\n",
        "    return raw_object\n",
        "\n",
        "# Create Raw objects for each cleaned entry (per participant)\n",
        "raw_dataset = []  # Will store (raw_object, label, participant)\n",
        "\n",
        "for idx, (df_clean, label, participant) in enumerate(cleaned_dataset):\n",
        "    print(f\"\\n🧠 Creating Raw object {idx + 1}/{len(cleaned_dataset)} - Participant: {participant}, Label: {label}\")\n",
        "\n",
        "    try:\n",
        "        raw = create_raw_object(df_clean)\n",
        "        raw = rename_eeg_channels(raw)\n",
        "        raw_dataset.append((raw, label, participant))\n",
        "        print(\"  ✅ Successfully created and renamed Raw object.\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Failed to create Raw object for {participant}, label {label}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBcUuqyKY4f1",
        "outputId": "2a69c205-08fb-4a05-eb16-09e14b7f98ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧪 Processing sample 1/1 - Participant: par.12, Label: ق\n",
            "  ✅ Filters and referencing applied.\n",
            "  ✅ No NaN or Inf values detected.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-ecc924ad68c6>:20: RuntimeWarning: The provided Raw instance does not seem to be referenced to a common average reference (CAR). ICLabel was designed to classify features extracted from an EEG dataset referenced to a CAR (see the 'set_eeg_reference()' method for Raw and Epochs instances).\n",
            "  ic_labels = label_components(raw, ica, method=\"iclabel\")\n",
            "<ipython-input-8-ecc924ad68c6>:20: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
            "  ic_labels = label_components(raw, ica, method=\"iclabel\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ✅ ICA completed. Excluded components: [0, 3, 7, 8, 11]\n",
            "  ✅ Successfully processed sample for par.12 (ق)\n"
          ]
        }
      ],
      "source": [
        "from mne.preprocessing import ICA\n",
        "from mne_icalabel import label_components\n",
        "import numpy as np\n",
        "\n",
        "# Apply filters and referencing to a Raw object\n",
        "def apply_filters_and_reference(raw):\n",
        "    raw.notch_filter(freqs=50.0, verbose=False)\n",
        "    raw.filter(l_freq=1.0, h_freq=50.0, verbose=False)\n",
        "    raw.set_eeg_reference('average', projection=True, verbose=False)\n",
        "    montage = mne.channels.make_standard_montage('standard_1020')\n",
        "    raw.set_montage(montage, verbose=False)\n",
        "    print(\"  ✅ Filters and referencing applied.\")\n",
        "    return raw\n",
        "\n",
        "# Perform ICA and clean artifacts for a Raw object\n",
        "def perform_ica(raw, brain_threshold=0.5):\n",
        "    ica = ICA(method='infomax', fit_params={'extended': True}, n_components=12, max_iter=1000, random_state=42)\n",
        "    ica.fit(raw, verbose=False)\n",
        "\n",
        "    ic_labels = label_components(raw, ica, method=\"iclabel\")\n",
        "\n",
        "    non_brain_components = [\n",
        "        idx for idx, (label, prob) in enumerate(zip(ic_labels['labels'], ic_labels['y_pred_proba']))\n",
        "        if label != 'brain' or prob < brain_threshold\n",
        "    ]\n",
        "\n",
        "    ica.exclude = non_brain_components\n",
        "    raw_cleaned = ica.apply(raw.copy(), verbose=False)\n",
        "\n",
        "    print(f\"  ✅ ICA completed. Excluded components: {non_brain_components}\")\n",
        "    return raw_cleaned\n",
        "\n",
        "# Check and clean NaN/Inf values from Raw data\n",
        "def clean_nan_inf(raw):\n",
        "    data = raw.get_data()\n",
        "    if np.isnan(data).any() or np.isinf(data).any():\n",
        "        print(\"  ⚠️ Detected NaN or Inf values.\")\n",
        "        for i in range(data.shape[0]):\n",
        "            channel_data = data[i, :]\n",
        "            channel_mean = np.nanmean(channel_data)\n",
        "            channel_data[np.isnan(channel_data)] = channel_mean\n",
        "            channel_data[np.isinf(channel_data)] = channel_mean\n",
        "            data[i, :] = channel_data\n",
        "        print(\"  ✅ NaN/Inf values replaced with channel means.\")\n",
        "    else:\n",
        "        print(\"  ✅ No NaN or Inf values detected.\")\n",
        "    raw._data = data\n",
        "    return raw\n",
        "\n",
        "# Final cleaned raw dataset: list of (raw_object, label, participant)\n",
        "cleaned_raw_dataset = []\n",
        "\n",
        "for idx, (raw_object, label, participant) in enumerate(raw_dataset):\n",
        "    print(f\"\\n🧪 Processing sample {idx + 1}/{len(raw_dataset)} - Participant: {participant}, Label: {label}\")\n",
        "    try:\n",
        "        raw = apply_filters_and_reference(raw_object)\n",
        "        raw = clean_nan_inf(raw)\n",
        "        raw = perform_ica(raw)\n",
        "        cleaned_raw_dataset.append((raw, label, participant))\n",
        "        print(f\"  ✅ Successfully processed sample for {participant} ({label})\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Failed to process sample for {participant} ({label}): {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vD4sRpyZBBG",
        "outputId": "17de6af2-ab1c-49f9-d93a-bd3ed513ef82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🧼 Interpolating + NaN Cleaning sample 1/1 - Participant: par.12, Label: ق\n",
            "  ✅ No bad channels to interpolate.\n",
            "  ✅ No NaN values detected in EEG data.\n",
            "Creating RawArray with float64 data, n_channels=12, n_times=1384\n",
            "    Range : 0 ... 1383 =      0.000 ...    10.805 secs\n",
            "Ready.\n",
            "  ✅ Successfully cleaned sample for par.12 (ق)\n"
          ]
        }
      ],
      "source": [
        "# Interpolation and NaN handling for Raw objects after ICA and filtering\n",
        "def interpolate_and_handle_nans(raw_cleaned):\n",
        "    try:\n",
        "        # Step 1: Interpolate bad channels (if any)\n",
        "        if raw_cleaned.info['bads']:\n",
        "            print(f\"  ⚠️ Interpolating bad channels: {raw_cleaned.info['bads']}\")\n",
        "            raw_cleaned.interpolate_bads(reset_bads=True)\n",
        "        else:\n",
        "            print(\"  ✅ No bad channels to interpolate.\")\n",
        "\n",
        "        # Step 2: Extract EEG data into DataFrame\n",
        "        eeg_data = pd.DataFrame(raw_cleaned.get_data().T, columns=raw_cleaned.ch_names)\n",
        "\n",
        "        # Step 3: Interpolate NaN values in the EEG data\n",
        "        if eeg_data.isna().sum().sum() > 0:\n",
        "            print(\"  ⚠️ NaN values found. Performing interpolation...\")\n",
        "            eeg_data = eeg_data.interpolate(method='linear', axis=0)\n",
        "            eeg_data = eeg_data.fillna(method='ffill').fillna(method='bfill')\n",
        "        else:\n",
        "            print(\"  ✅ No NaN values detected in EEG data.\")\n",
        "\n",
        "        # Step 4: Recreate Raw object with cleaned data\n",
        "        raw_cleaned = mne.io.RawArray(eeg_data.T.to_numpy(), raw_cleaned.info)\n",
        "        return raw_cleaned\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Error during interpolation and NaN handling: {e}\")\n",
        "        return raw_cleaned\n",
        "\n",
        "\n",
        "# Final list of fully cleaned raw samples (after ICA + interpolation)\n",
        "fully_cleaned_raw_dataset = []\n",
        "\n",
        "for idx, (raw_object, label, participant) in enumerate(cleaned_raw_dataset):\n",
        "    print(f\"\\n🧼 Interpolating + NaN Cleaning sample {idx + 1}/{len(cleaned_raw_dataset)} - Participant: {participant}, Label: {label}\")\n",
        "\n",
        "    try:\n",
        "        cleaned_raw = interpolate_and_handle_nans(raw_object)\n",
        "        fully_cleaned_raw_dataset.append((cleaned_raw, label, participant))\n",
        "        print(f\"  ✅ Successfully cleaned sample for {participant} ({label})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Failed to process sample for {participant} ({label}): {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVdAgny7ZMDC",
        "outputId": "8c8020d6-5c1b-452b-d2c3-46a96b38a3ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔄 Normalizing sample 1/1 - Participant: par.12, Label: ق\n",
            "  ✅ Applied Z-score normalization.\n",
            "  ✅ Normalized sample for par.12 (ق)\n"
          ]
        }
      ],
      "source": [
        "# Function to apply Z-score normalization to EEG data\n",
        "def z_score_normalize_eeg_data(raw):\n",
        "    \"\"\"\n",
        "    Normalize the EEG data in the Raw object using Z-score normalization\n",
        "    (zero mean, unit variance) per channel.\n",
        "    \"\"\"\n",
        "    eeg_data = raw.get_data()\n",
        "    mean = np.mean(eeg_data, axis=1, keepdims=True)\n",
        "    std = np.std(eeg_data, axis=1, keepdims=True)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    std[std == 0] = 1e-10\n",
        "\n",
        "    normalized_data = (eeg_data - mean) / std\n",
        "    raw._data = normalized_data\n",
        "    print(\"  ✅ Applied Z-score normalization.\")\n",
        "    return raw\n",
        "\n",
        "# Final dataset with Z-score normalization applied\n",
        "z_score_normalized_dataset = []\n",
        "\n",
        "for idx, (raw_object, label, participant) in enumerate(fully_cleaned_raw_dataset):\n",
        "    print(f\"\\n🔄 Normalizing sample {idx + 1}/{len(fully_cleaned_raw_dataset)} - Participant: {participant}, Label: {label}\")\n",
        "\n",
        "    try:\n",
        "        normalized_raw = z_score_normalize_eeg_data(raw_object)\n",
        "        z_score_normalized_dataset.append((normalized_raw, label, participant))\n",
        "        print(f\"  ✅ Normalized sample for {participant} ({label})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Failed to normalize sample for {participant} ({label}): {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKXO1WjpZRCe",
        "outputId": "ab09e94e-907a-454a-f911-a0358e81958c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔄 Segmenting sample 1/1 - Participant: par.12, Label: ق\n",
            "  ℹ️ Partial segment (184 samples) ignored for par.12 (ق)\n",
            "  ✅ 1 full segments created for par.12 (ق)\n",
            "\n",
            "✅ Segmented letter data saved to 'segmented_letter_data.csv'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Set segment length (e.g., 1200 samples = 9.375 seconds if FS = 128)\n",
        "segment_length = 1200\n",
        "\n",
        "# Final dataset: list of (segment_array, label, participant)\n",
        "segmented_dataset = []\n",
        "\n",
        "# Process each sample\n",
        "for idx, (raw_object, label, participant) in enumerate(z_score_normalized_dataset):\n",
        "    print(f\"\\n🔄 Segmenting sample {idx + 1}/{len(z_score_normalized_dataset)} - Participant: {participant}, Label: {label}\")\n",
        "\n",
        "    try:\n",
        "        data = raw_object.get_data().T  # Shape: (time, channels)\n",
        "        num_segments = len(data) // segment_length\n",
        "\n",
        "        for i in range(num_segments):\n",
        "            segment = data[i * segment_length: (i + 1) * segment_length]  # (segment_length, channels)\n",
        "            segmented_dataset.append((segment, label, participant))\n",
        "\n",
        "        if len(data) % segment_length != 0:\n",
        "            partial_len = len(data) % segment_length\n",
        "            print(f\"  ℹ️ Partial segment ({partial_len} samples) ignored for {participant} ({label})\")\n",
        "\n",
        "        print(f\"  ✅ {num_segments} full segments created for {participant} ({label})\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ❌ Failed to segment sample for {participant} ({label}): {e}\")\n",
        "\n",
        "\n",
        "# 🔽 Convert to flat DataFrame for CSV export\n",
        "flat_data = []\n",
        "for segment_array, label, participant in segmented_dataset:\n",
        "    flat_segment = segment_array.flatten()  # shape: (segment_length * channels,)\n",
        "    row = list(flat_segment) + [label, participant]\n",
        "    flat_data.append(row)\n",
        "\n",
        "# Generate column names\n",
        "num_features = segment_array.shape[0] * segment_array.shape[1]  # time * channels\n",
        "column_names = [f\"feature_{i}\" for i in range(num_features)] + [\"label\", \"participant\"]\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(flat_data, columns=column_names)\n",
        "\n",
        "# 💾 Save to CSV\n",
        "csv_filename = \"segmented_letter_data.csv\"\n",
        "df.to_csv(csv_filename, index=False)\n",
        "print(f\"\\n✅ Segmented letter data saved to '{csv_filename}'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
