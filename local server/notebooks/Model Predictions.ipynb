{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj2WXuOAxfIn",
        "outputId": "70b68713-92f6-41ff-eaea-427276f359af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Shape after trimming: (1, 14400)\n",
            "\n",
            "üîö Last few columns of the DataFrame:\n",
            "   feature_14390  feature_14391  feature_14392  feature_14393  feature_14394  \\\n",
            "0       1.492517       1.049635       0.005963      -0.036129       0.865046   \n",
            "\n",
            "   feature_14395  feature_14396  feature_14397  feature_14398  feature_14399  \n",
            "0       0.919642      -0.263105       1.116019      -0.525958       0.155263  \n",
            "üî¢ Last column indices: ['feature_14390', 'feature_14391', 'feature_14392', 'feature_14393', 'feature_14394', 'feature_14395', 'feature_14396', 'feature_14397', 'feature_14398', 'feature_14399']\n",
            "‚úÖ Final input shape to model: (1, 12, 1200, 1)\n",
            "üßº NaNs: 0, Infs: 0\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "üß† Prediction probabilities for first sample: [9.59261670e-04 7.55274415e-01 2.81864312e-03 3.79343075e-03\n",
            " 3.07595101e-03 2.48910603e-03 6.36705104e-03 2.36299615e-02\n",
            " 3.07933486e-04 9.30671860e-03 4.10350971e-03 1.31583195e-02\n",
            " 3.34845227e-03 2.78735976e-03 5.47834486e-03 4.25632671e-03\n",
            " 2.98235267e-02 3.91069613e-03 2.22622650e-03 2.28918549e-02\n",
            " 1.80921089e-02 5.82908746e-03 6.36597979e-04 2.66185869e-02\n",
            " 9.36053973e-03 1.80817465e-03 3.52570554e-03 3.28861363e-03\n",
            " 1.52920680e-02 2.83682439e-03 1.27043659e-02]\n",
            "\n",
            "üî§ Predicted Letters:\n",
            "  Sample 1: ÿßŸî\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "import random\n",
        "\n",
        "# Set random seeds to ensure deterministic behavior\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Constants\n",
        "NUM_CHANNELS = 12  # Number of EEG channels\n",
        "SEGMENT_LENGTH = 1200\n",
        "MODEL_PATH = r\"/content/final_eegnet_model.keras\"\n",
        "LABEL_ENCODER_PATH = r\"/content/label_encoder_final.pkl\"\n",
        "\n",
        "# --------------------------------------\n",
        "# Step 1: Load CSV Data\n",
        "# --------------------------------------\n",
        "csv_file = \"/content/segmented_letter_data.csv\"  # Replace with your actual CSV file path\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Remove non-numeric columns (label and participant)\n",
        "df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "# Trim extra columns if not divisible by segment_length * channels\n",
        "num_columns = df.shape[1]\n",
        "expected_features = SEGMENT_LENGTH * NUM_CHANNELS\n",
        "columns_to_trim = num_columns % expected_features\n",
        "\n",
        "if columns_to_trim != 0:\n",
        "    df = df.iloc[:, :-columns_to_trim]  # Trim the extra columns\n",
        "\n",
        "print(f\"‚úÖ Shape after trimming: {df.shape}\")\n",
        "\n",
        "print(\"\\nüîö Last few columns of the DataFrame:\")\n",
        "print(df.iloc[:, -10:].head())  # Show the last 10 columns for the first few rows\n",
        "print(f\"üî¢ Last column indices: {df.columns[-10:].tolist()}\")  # Print their names/indexes\n",
        "\n",
        "\n",
        "# Reshape: (samples, segment_length, channels)\n",
        "X_temp = df.values.reshape(-1, SEGMENT_LENGTH, NUM_CHANNELS)\n",
        "\n",
        "# Transpose to match model's expected shape: (samples, channels, time_steps, 1)\n",
        "X_new = np.transpose(X_temp, (0, 2, 1))      # Now (samples, 12, 1200)\n",
        "X_new = X_new[..., np.newaxis]              # Now (samples, 12, 1200, 1)\n",
        "\n",
        "print(f\"‚úÖ Final input shape to model: {X_new.shape}\")\n",
        "\n",
        "# --------------------------------------\n",
        "# Step 2: Load Model and Label Encoder\n",
        "# --------------------------------------\n",
        "model = load_model(MODEL_PATH)\n",
        "model.trainable = False\n",
        "\n",
        "with open(LABEL_ENCODER_PATH, \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "# --------------------------------------\n",
        "# Step 3: Predict\n",
        "# --------------------------------------\n",
        "# Optional: Check for NaN or Inf values\n",
        "print(f\"üßº NaNs: {np.isnan(X_new).sum()}, Infs: {np.isinf(X_new).sum()}\")\n",
        "X_new = np.nan_to_num(X_new)\n",
        "\n",
        "# Run prediction\n",
        "y_pred_probs = model.predict(X_new)\n",
        "print(\"üß† Prediction probabilities for first sample:\", y_pred_probs[0])\n",
        "\n",
        "# Decode predicted classes\n",
        "y_pred_labels = np.argmax(y_pred_probs, axis=-1)\n",
        "predicted_letters = label_encoder.inverse_transform(y_pred_labels)\n",
        "\n",
        "# Display predictions\n",
        "print(\"\\nüî§ Predicted Letters:\")\n",
        "for i, letter in enumerate(predicted_letters):\n",
        "    print(f\"  Sample {i+1}: {letter}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
